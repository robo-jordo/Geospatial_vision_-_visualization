{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import csv\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = []\n",
    "lon = []\n",
    "alt = []\n",
    "intensity = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLA_to_XYZ(Lat,Lon,Alt,intensity):\n",
    "    ''' Takes Latitude, Longitude and Altitdue and converts this data into\n",
    "    x,y and z cartesion co-ordinates. Returns intensity as is.'''\n",
    "    r_earth = (6378.137*1000)\n",
    "    LatCos = np.cos(Lat*np.pi/180)\n",
    "    LatSin = np.sin(Lat*np.pi/180)\n",
    "    LonCos = np.cos(Lon*np.pi/180)\n",
    "    LonSin = np.sin(Lon*np.pi/180)\n",
    "    f = 1.0 / 298.257224\n",
    "    C = 1.0/ np.sqrt(LatCos**2 + ((1-f)**2)*((LatSin)**2))\n",
    "    S = ((1.0 - f)**2)*(C)\n",
    "    x = (r_earth*C)*LatCos*LonCos\n",
    "    y = (r_earth*C)*LatCos*LonSin\n",
    "    z = Alt\n",
    "    return x,y,z,intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    ''' This function reads the file -\"filename\"- and appends \n",
    "    the data to the lat,lon,alt and intensity arrays '''\n",
    "    global lat,lon,alt,intensity\n",
    "    with open(filename) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter =' ')\n",
    "        for row in reader:\n",
    "            lat.append(float(row[0]))\n",
    "            lon.append(float(row[1]))\n",
    "            alt.append(float(row[2]))\n",
    "            intensity.append(float(row[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "readfile(\"final_project_data/final_project_point_cloud.fuse\")\n",
    "points_xyzi = np.ones((len(lat),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(lat)):\n",
    "    points_xyzi[i] = LLA_to_XYZ(lat[i],lon[i],alt[i],intensity[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430736, 4)\n"
     ]
    }
   ],
   "source": [
    "print(points_xyzi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.90370042\n",
      "11.02826286\n",
      "226.2948\n",
      "4.0\n",
      "[4.36390869e+06 8.50492097e+05 2.26294800e+02 4.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(lat[31])\n",
    "print(lon[31])\n",
    "print(alt[31])\n",
    "print(intensity[31])\n",
    "print(points_xyzi[31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_point_cloud_object(array,name):\n",
    "    ''' Takes array of point cloud (x,y,z) data and writes it to a \n",
    "    point cloud object file viewable in meshLab'''\n",
    "    pc_object = open(name,\"w\")\n",
    "    for j in array:\n",
    "        pc_object.write(\"v \"+str(j[0])+\" \"+str(j[1])+\" \"+str(j[2])+\"\\n\")\n",
    "    pc_object.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_point_cloud_object(points_xyzi,\"All_data.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jordan/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "X_scaled = preprocessing.scale(points_xyzi[ 0:400000 , 0:3])\n",
    "X_norm = preprocessing.normalize(points_xyzi[:, 0:3], norm='l2')\n",
    "\n",
    "#y_pred = DBSCAN(eps=0.3, min_samples=10).fit_predict(X_norm)\n",
    "#y_pred = AgglomerativeClustering(n_clusters=2,affinity=\"euclidean\",linkage=\"ward\").fit_predict(X_norm)\n",
    "y_pred = KMeans(n_clusters=2).fit_predict(points_xyzi[:, 2].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def planar_filter(xyzi, grid_size, lower_bound):\n",
    "\n",
    "    scale = 1 / grid_size\n",
    "    scale = int(scale) if scale > 1 else scale\n",
    "\n",
    "    # Count height for each grid_size\n",
    "    d = collections.defaultdict(list)\n",
    "    xy = np.round(xyzi[:, 0:2] * scale)\n",
    "    for idx in range(xyzi.shape[0]):\n",
    "        x, y = xy[idx, :]\n",
    "        z = xyzi[idx, 2]\n",
    "        d[(x, y)].append((idx, z))\n",
    "\n",
    "    # Filter the grid. Remove those with large different in z axis\n",
    "    poi = []\n",
    "    for xy, list_of_idx_and_z in d.items():\n",
    "        list_idx, list_z = zip(*list_of_idx_and_z)\n",
    "        if max(list_z) - min(list_z) >= lower_bound:\n",
    "            poi.extend(list_idx)\n",
    "\n",
    "    return poi\n",
    "\n",
    "poi = planar_filter(points_xyzi, grid_size=0.5, lower_bound=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyza_planar = points_xyzi[poi, :]\n",
    "y_pred = KMeans(n_clusters=8).fit_predict(xyza_planar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using open3d - creating open3d object\n",
    "p = o3d.geometry.PointCloud()\n",
    "# print(points_xyzi.shape)\n",
    "a = points_xyzi[ : , 0:3][points_xyzi[ : , 2].argsort()]\n",
    "p.points = o3d.utility.Vector3dVector(xyza_planar[ : , 0:3])\n",
    "# help(o3d.geometry.PointCloud().colors)\n",
    "colours = np.array([[255,255,0],[255,0,255],[0,255,255],[255,0,0],[0,255,0],[0,0,255],[128,255,0],[255,128,0],[0,128,255],[0,0,0],[255,255,0],[255,0,255],[0,255,255],[255,0,0],[0,255,0],[0,0,255],[128,255,0],[255,128,0],[0,128,255],[0,0,0]])\n",
    "intens = np.zeros((np.size(points_xyzi[ : , 3]),3))\n",
    "scaled_intensity = points_xyzi[ : , 3]/255\n",
    "# intens[:,0] = np.reshape(scaled_intensity,-1)\n",
    "# intens[:,0] = np.zeros(430736,)\n",
    "# intens[:,1] = np.reshape(scaled_intensity,-1)\n",
    "# intens[:,1] = np.zeros(430736,)\n",
    "# # # intens[:,2] = np.reshape(scaled_intensity,-1)\n",
    "for i in range(len(y_pred)):\n",
    "    intens[i] = colours[y_pred[i]]\n",
    "# intens[:150000,0] = np.zeros(150000,)\n",
    "# intens[:150000,1] = np.zeros(150000,)\n",
    "# intens[:150000,2] = np.ones(150000,)\n",
    "# intens[150000:300000,1] = np.zeros(150000,)\n",
    "# intens[150000:300000,2] = np.zeros(150000,)\n",
    "# intens[150000:300000,0] = np.ones(150000,)\n",
    "# intens[300000:,2] = np.zeros(430736-300000,)\n",
    "# intens[300000:,0] = np.zeros(430736-300000,)\n",
    "# intens[300000:,1] = np.ones(430736-300000,)\n",
    "\n",
    "\n",
    "p.colors = o3d.utility.Vector3dVector(intens)\n",
    "#p.colors = o3d.utility.Vector3dVector(points_xyzi[ : , 3])\n",
    "o3d.io.write_point_cloud(\"./Alldata.ply\", p)\n",
    "o3d.visualization.draw_geometries([p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ethan splines here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430736,)\n"
     ]
    }
   ],
   "source": [
    "print((intens[:,0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#Downsampling by voxel\n",
    "down_voxel = o3d.geometry.voxel_down_sample(p, voxel_size=0.8)\n",
    "o3d.io.write_point_cloud(\"./Downsampled_voxel.ply\", down_voxel)\n",
    "# o3d.visualization.draw_geometries([down_voxel])\n",
    "\n",
    "\n",
    "#Downsampling uniformly\n",
    "down_uniform = o3d.geometry.uniform_down_sample(p, every_k_points=5)\n",
    "o3d.io.write_point_cloud(\"./Downsampled_uniform.ply\", down_uniform)\n",
    "# o3d.visualization.draw_geometries([down_uniform])\n",
    "\n",
    "#Downsampling statistical outlier removal\n",
    "down_stats, ind = o3d.geometry.statistical_outlier_removal(down_voxel,nb_neighbors=50,std_ratio=5.0)\n",
    "# inliers = o3d.geometry.select_down_sample(down_stats, ind)\n",
    "o3d.io.write_point_cloud(\"./Downsampled_Removed_Stat_Outliers.ply\", down_stats)\n",
    "o3d.visualization.draw_geometries([down_stats])\n",
    "print(np.size(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292208\n",
      "39780\n",
      "39630\n"
     ]
    }
   ],
   "source": [
    "print(np.size(p.points))\n",
    "print(np.size(down_voxel.points))\n",
    "print(np.size(down_stats.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.36385641e+06 8.50503315e+05 2.25276640e+02]\n"
     ]
    }
   ],
   "source": [
    "xyz_load = np.asarray(down_voxel.points)\n",
    "print(xyz_load[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = preprocessing.normalize(xyz_load, norm='l2')\n",
    "\n",
    "#y_pred = DBSCAN(eps=0.3, min_samples=10).fit_predict(X_norm)\n",
    "#y_pred = AgglomerativeClustering(n_clusters=2,affinity=\"euclidean\",linkage=\"ward\").fit_predict(X_norm)\n",
    "y_pred = KMeans(n_clusters=5).fit_predict(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.size(xyz_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using open3d - creating open3d object\n",
    "p1 = o3d.geometry.PointCloud()\n",
    "\n",
    "p1.points = o3d.utility.Vector3dVector(xyz_load)\n",
    "# help(o3d.geometry.PointCloud().colors)\n",
    "#colours = np.array([[255,255,0],[255,0,255],[0,255,255],[255,0,0],[0,255,0],[0,0,255],[128,255,0],[255,128,0],[0,128,255],[0,0,0],[255,255,0],[255,0,255],[0,255,255],[255,0,0],[0,255,0],[0,0,255],[128,255,0],[255,128,0],[0,128,255],[0,0,0]])\n",
    "intens1 = np.zeros((np.size(xyz_load),3))\n",
    "#scaled_intensity = points_xyzi[ : , 3]/255\n",
    "# intens[:,0] = np.reshape(scaled_intensity,-1)\n",
    "# intens[:,0] = np.zeros(430736,)\n",
    "# intens[:,1] = np.reshape(scaled_intensity,-1)\n",
    "# intens[:,1] = np.zeros(430736,)\n",
    "# # intens[:,2] = np.reshape(scaled_intensity,-1)\n",
    "# for i in range(len(y_pred)):\n",
    "#     intens[i] = colours[y_pred[i]]\n",
    "# intens[:150000,0] = np.zeros(150000,)\n",
    "# intens[:150000,1] = np.zeros(150000,)\n",
    "# intens[:150000,2] = np.ones(150000,)\n",
    "# intens[150000:300000,1] = np.zeros(150000,)\n",
    "# intens[150000:300000,2] = np.zeros(150000,)\n",
    "# intens[150000:300000,0] = np.ones(150000,)\n",
    "# intens[300000:,2] = np.zeros(430736-300000,)\n",
    "# intens[300000:,0] = np.zeros(430736-300000,)\n",
    "# intens[300000:,1] = np.ones(430736-300000,)\n",
    "\n",
    "\n",
    "p1.colors = o3d.utility.Vector3dVector(intens1)\n",
    "#p.colors = o3d.utility.Vector3dVector(points_xyzi[ : , 3])\n",
    "o3d.io.write_point_cloud(\"./Alldata1.ply\", p1)\n",
    "o3d.visualization.draw_geometries([p1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(intens1[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the normals\n",
    "normals = p\n",
    "#Play with radius and nn numbers\n",
    "o3d.geometry.estimate_normals(normals,search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.2,max_nn=10)) \n",
    "o3d.visualization.draw_geometries([normals]) #press n to see the normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(points_xyzi[0])\n",
    "print(points_xyzi[1])  \n",
    "print(points_xyzi[2])  \n",
    "print(points_xyzi[50000])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Range x\")\n",
    "print(np.max(points_xyzi[:,0]))\n",
    "print(np.min(points_xyzi[:,0]))\n",
    "print(\"Range y\")\n",
    "print(np.max(points_xyzi[:,1]))\n",
    "print(np.min(points_xyzi[:,1]))\n",
    "print(\"Range z\")\n",
    "print(np.max(points_xyzi[:,2]))\n",
    "print(np.min(points_xyzi[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
